apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: river-kafka
  namespace: kafka
spec:
  kafka:
    version: 3.8.0
    replicas: 3
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
      - name: external
        port: 9094
        type: nodeport
        tls: false
        configuration:
          preferredNodePortAddressType: InternalIP
    config:
      # KRaft mode configuration
      process.roles: "broker,controller"
      node.id: 1
      controller.quorum.voters: "1@river-kafka-kafka-0.river-kafka-kafka-brokers.kafka.svc.cluster.local:9093,2@river-kafka-kafka-1.river-kafka-kafka-brokers.kafka.svc.cluster.local:9093,3@river-kafka-kafka-2.river-kafka-kafka-brokers.kafka.svc.cluster.local:9093"
      controller.listener.names: "CONTROLLER"
      listener.security.protocol.map: "CONTROLLER:PLAINTEXT,REPLICATION:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL"

      # Performance settings
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      default.replication.factor: 3
      min.insync.replicas: 2
      inter.broker.protocol.version: "3.8"

      # Log settings optimized for large images (50MB)
      log.message.format.version: "3.8"
      num.network.threads: 3
      num.io.threads: 8
      socket.send.buffer.bytes: 102400 # 100 KB
      socket.receive.buffer.bytes: 102400 # 100 KB
      socket.request.max.bytes: 52428800 # 50MB for large images
      
      # Message size settings for 50MB images
      message.max.bytes: 52428800           # 50MB max message size
      replica.fetch.max.bytes: 52428800     # Replication buffer
      fetch.max.bytes: 52428800             # Consumer fetch size
      log.segment.bytes: 1073741824         # 1GB log segments

      # Auto-create topics for development
      auto.create.topics.enable: true
      delete.topic.enable: true
    storage:
      type: jbod
      volumes:
        - id: 0
          type: persistent-claim
          size: 5Gi
          deleteClaim: false
    resources:
      requests:
        memory: 1Gi
        cpu: "500m"
      limits:
        memory: 2Gi
        cpu: "1000m"
    jvmOptions:
      -Xms: 512m
      -Xmx: 1g
    metricsConfig:
      type: jmxPrometheusExporter
      valueFrom:
        configMapKeyRef:
          name: kafka-metrics
          key: kafka-metrics-config.yml
  # No separate Zookeeper - using KRaft mode
  entityOperator:
    topicOperator:
      resources:
        requests:
          memory: 256Mi
          cpu: "100m"
        limits:
          memory: 512Mi
          cpu: "200m"
    userOperator:
      resources:
        requests:
          memory: 256Mi
          cpu: "100m"
        limits:
          memory: 512Mi
          cpu: "200m"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-metrics
  namespace: kafka
data:
  kafka-metrics-config.yml: |
    # See https://github.com/prometheus/jmx_exporter for more info about JMX Prometheus Exporter metrics
    lowercaseOutputName: true
    rules:
    # Special cases and very specific rules
    - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
      labels:
       clientId: "$3"
       topic: "$4"
       partition: "$5"
    - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
      name: kafka_server_$1_$2
      type: GAUGE
      labels:
       clientId: "$3"
       broker: "$4:$5"
    - pattern: kafka.server<type=(.+), cipher=(.+), protocol=(.+), listener=(.+), networkProcessor=(.+)><>connections
      name: kafka_server_$1_connections_tls_info
      type: GAUGE
      labels:
        cipher: "$2"
        protocol: "$3"
        listener: "$4"
        networkProcessor: "$5"
    - pattern: kafka.server<type=(.+), clientSoftwareName=(.+), clientSoftwareVersion=(.+), listener=(.+), networkProcessor=(.+)><>connections
      name: kafka_server_$1_connections_software
      type: GAUGE
      labels:
        clientSoftwareName: "$2"
        clientSoftwareVersion: "$3"
        listener: "$4"
        networkProcessor: "$5"
    - pattern: "kafka.server<type=(.+), listener=(.+), networkProcessor=(.+)><>(.+):"
      name: kafka_server_$1_$4
      type: GAUGE
      labels:
       listener: "$2"
       networkProcessor: "$3"
    - pattern: kafka.server<type=(.+), listener=(.+)><>(.+):
      name: kafka_server_$1_$3
      type: GAUGE
      labels:
       listener: "$2"
    # Generic rules
    - pattern: kafka.(\w+)<type=(.+), name=(.+)><>Count
      name: kafka_$1_$2_$3_total
      type: COUNTER
    - pattern: kafka.(\w+)<type=(.+), name=(.+)><>(\d+)thPercentile
      name: kafka_$1_$2_$3
      type: GAUGE
      labels:
        quantile: "0.$4"
    - pattern: kafka.(\w+)<type=(.+), name=(.+)><>(\w+)
      name: kafka_$1_$2_$3_$4
      type: GAUGE
